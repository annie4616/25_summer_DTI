{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8ae1a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.9.23 (main, Jun  5 2025, 13:40:20) \n",
      "[GCC 11.2.0]\n",
      "PyTorch version:2.8.0+cu128\n",
      "cuda version:   12.8\n",
      "cudnn version:  91002\n",
      "\u001b[33m  DEPRECATION: Building 'vapeplot' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'vapeplot'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting rdkit\n",
      "  Downloading rdkit-2025.3.5-cp39-cp39-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/miniconda3/envs/25DTI/lib/python3.9/site-packages (from rdkit) (2.0.2)\n",
      "Requirement already satisfied: Pillow in /usr/local/miniconda3/envs/25DTI/lib/python3.9/site-packages (from rdkit) (11.3.0)\n",
      "Downloading rdkit-2025.3.5-cp39-cp39-manylinux_2_28_x86_64.whl (36.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rdkit\n",
      "Successfully installed rdkit-2025.3.5\n",
      "torch_geometric version:2.6.1\n"
     ]
    }
   ],
   "source": [
    "# GCN model\n",
    "# 환경설정을 PIP 기반으로 간략하게 변경하였음\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "# Check the compatibility of the python and torch version (Comments are wriiten @2024.08.30)\n",
    "print(\"Python version: {}\".format(sys.version))                    # 3.10.12\n",
    "print(\"PyTorch version:{}\".format(torch.__version__))              # 2.4.0+cu124\n",
    "print(\"cuda version:   {}\".format(torch.version.cuda))             # 12.1\n",
    "print(\"cudnn version:  {}\".format(torch.backends.cudnn.version())) # 8700\n",
    "\n",
    "# Install required python libraries\n",
    "!pip install -q pyg_lib -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q torch_scatter -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q torch_sparse  -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q torch_cluster -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q torch_spline_conv -f https://data.pyg.org/whl/torch-2.4.0+cu121.html\n",
    "!pip install -q torch-geometric\n",
    "!pip install -q e3nn vapeplot\n",
    "!pip install rdkit\n",
    "\n",
    "# Check the compatibilites of the torch-geometric\n",
    "import torch_geometric as pyg\n",
    "print(\"torch_geometric version:{}\".format(pyg.__version__))        # 2.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66ba2d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json,pickle\n",
    "import networkx as nx\n",
    "from math import sqrt\n",
    "from random import shuffle\n",
    "from collections import OrderedDict\n",
    "from scipy import stats\n",
    "from IPython.display import SVG\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a248d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import rdDepictor\n",
    "from rdkit.Chem.Draw import rdMolDraw2D\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from torch_geometric import data as DATA\n",
    "from torch_geometric.data import InMemoryDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_max_pool as gmp\n",
    "from torch_geometric.nn import GCNConv, GATConv, GINConv, global_add_pool\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "\n",
    "# 시각화 라이브러리\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246b5419",
   "metadata": {},
   "source": [
    "#### 원자 특성 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66c521d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input{0} not allowed in set {1}:\".format(x, allowable_set))\n",
    "    return list(map(lambda s: x == s, allowable_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d232130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_encoding_unk(x, allowable_set):\n",
    "    # allowable set에 있지 않으면 마지막 요소로 매핑\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return list(map(lambda s: x == s, allowable_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea054cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def atom_features(atom):\n",
    "    return np.array(feature_encoding_unk(atom.GetSymbol(),['C', 'N', 'O', 'S', 'F', 'Si', 'P', 'Cl', 'Br', 'Mg', 'Na','Ca', 'Fe', 'As', 'Al', 'I', 'B', 'V', 'K', 'Tl', 'Yb','Sb', 'Sn', 'Ag', 'Pd', 'Co', 'Se', 'Ti', 'Zn', 'H','Li', 'Ge', 'Cu', 'Au', 'Ni', 'Cd', 'In', 'Mn', 'Zr','Cr', 'Pt', 'Hg', 'Pb', 'Unknown']) +\n",
    "                    feature_encoding(atom.GetDegree(), [0,1,2,3,4,5,6,7,8,9,10]) +\n",
    "                    feature_encoding_unk(atom.GetDegree(), [0,1,2,3,4,5,6,7,8,9,10]) +\n",
    "                    feature_encoding_unk(atom.GetTotalNumHs(),[0,1,2,3,4,5,6,7,8,9,10]) +\n",
    "                    feature_encoding_unk(atom.GetImplicitValence(),[0,1,2,3,4,5,6,7,8,9,10]) +\n",
    "                    [atom.GetIsAromatic()]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d59963",
   "metadata": {},
   "source": [
    "#### SMILES to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7c473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns: 원자 개수, 원자 특성 행렬, 인접 행렬\n",
    "def smiles_to_graph(smiles):\n",
    "    # 문자열 -> 그래프\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "\n",
    "    # 원자 개수 저장\n",
    "    c_size = mol.GetNumAtoms()\n",
    "    features = []\n",
    "\n",
    "    for atom in mol.GetAtoms():\n",
    "        feature = atom_features(atom)\n",
    "        features.append(feature/sum(feature)) # 정규화\n",
    "\n",
    "    # 엣지 - 시작 원자 정보와 끝 원자 정보\n",
    "    edges = []\n",
    "    for bond in mol.GetBonds():\n",
    "        edges.append([bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()])\n",
    "\n",
    "    # nx라이브러리를 이용해 데이터를 방향 그래프로 변환\n",
    "    g = nx.Graph(edges).to_directed()\n",
    "    edge_index = []\n",
    "    for e1, e2 in g.edges:\n",
    "        edge_index.append([e1, e2])\n",
    "\n",
    "    return c_size, features, edge_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18115c61",
   "metadata": {},
   "source": [
    "#### Protein Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b18651dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 표적 염기서열을 이루는 알파벳(25자) vocabulary\n",
    "seq_voc = \"ABCDEFGHIKLMNOPQRSTUVWXYZ\"\n",
    "\n",
    "# 정수로 매핑\n",
    "seq_dict = {v:{i+1} for i,v in enumerate(seq_voc)}\n",
    "seq_dict_len = len(seq_dict)\n",
    "\n",
    "# padding\n",
    "max_seq_len = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd966144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# protein representation\n",
    "def seq_cat(prot):\n",
    "    # 0행렬 생성\n",
    "    x = np.zeros(max_seq_len)\n",
    "    for i, ch in enumerate(prot[:max_seq_len]):\n",
    "        x[i] = seq_dict[ch]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59407078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # datasets\n",
    "# all_prots = []\n",
    "# datasets = ['kiba']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "180f025e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinESMLinear(nn.Module):\n",
    "    def __init__(self, in_dim=1280, out=256, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim,1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, out)\n",
    "        )\n",
    "    def forward(self, esm_repr): # [B, 1280] 형태로 넣어주기 (mean-pooled)\n",
    "        return self.net(esm_repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c81906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DTIDataset(InMemoryDataset):\n",
    "#     def __init__(self, csv_path, esm, transform = None, pre_transform=None):\n",
    "#         super().__init__('.', transform, pre_transform)\n",
    "#         self.df = pd.read_csv(csv_path)\n",
    "#         if isinstance(esm, str):\n",
    "#             if esm.endswith('.npy'):\n",
    "#                 self.esm = np.load(esm, allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ce936",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, n_output = 1, n_filters=32, embed_dim=128, num_features_xd=78, num_features_xt = 25, output_dim=128, dropout=0.2, esm_in_dim=1280):\n",
    "        super(GCN, self).__init__()\n",
    "        self.n_output = n_output # 모델의 출력은 숫자 1개\n",
    "\n",
    "        # Drug Representation\n",
    "        self.conv1 = GCNConv(num_features_xd, num_features_xd)\n",
    "        self.conv2 = GCNConv(num_features_xd, num_features_xd*2)\n",
    "        self.conv3 = GCNConv(num_features_xd*2, num_features_xd*4)\n",
    "\n",
    "        # fully connected layer - 1024차원으로 변환\n",
    "        self.fc_g1 = torch.nn.Linear(num_features_xd*4, 1024)\n",
    "        self.fc_g2 = torch.nn.Linear(1024, output_dim)\n",
    "\n",
    "        # activation function\n",
    "        self.relu = nn.ReLU()\n",
    "        #Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # Protein Representation(ESM -> MLP proj)\n",
    "        self.protein_proj = nn.Sequential(\n",
    "            nn.Linear(esm_in_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(1024, output_dim)\n",
    "        )\n",
    "\n",
    "        # Drug + Protein Representation fusion\n",
    "        self.fc1 = nn.Linear(2*output_dim, 1024)\n",
    "        self.fc2 = nn.Linear(1024,512)\n",
    "\n",
    "        self.out = nn.Linear(512, self.n_output)\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        # target = data.target\n",
    "\n",
    "        # GCN Layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = gmp(x, batch)\n",
    "\n",
    "        x = self.relu(self.fc_g1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_g2(x)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        xt = data.protein_esm.float()\n",
    "        xt = self.protein_proj(xt)\n",
    "\n",
    "        # Drug, Protein Representation을 torch.cat을 이용해 하나로 결합\n",
    "        xc = torch.cat((x, xt), 1)\n",
    "\n",
    "        # 하나의 출력값 구하기\n",
    "        xc = self.fc1(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        xc = self.fc2(xc)\n",
    "        xc = self.relu(xc)\n",
    "        xc = self.dropout(xc)\n",
    "        out = self.out(xc)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980e6440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_data_item(graph_x, edge_index, y, esm_vec):\n",
    "#     d = Data(\n",
    "#         x=torch.tensor(graph_x, dtype=torch.float),\n",
    "#         edge_index=torch.tensor(edge_index, dtype=torch.long),\n",
    "#         y=torch.tensor(y, dtype=torch.float)\n",
    "#     )\n",
    "#     d.protein_esm = torch.tensor(esm_vec, dtype=torch.float)\n",
    "#     return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7eb921",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    print('Training on {} samples...'.format(len(train_loader.dataset)))\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        loss = loss_fn(output, data.y.view(-1,1).float().to(device))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx%LOG_INTERVAL == 0:\n",
    "            print('Train epoch: {}[{}/{} ({:.0f}%)]|tLoss: {:.6f}'.format(epoch,\n",
    "                                                                          batch_idx*len(data.x),\n",
    "                                                                          len(train_loader.dataset),\n",
    "                                                                          100.*batch_idx/len(train_loader),\n",
    "                                                                          loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18e3729",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicting(model, device, loader):\n",
    "    model.eval()\n",
    "    total_preds = torch.Tensor()\n",
    "\n",
    "    print('Make prediction for {} samples...'.format(len(loader.dataset)))\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            total_preds = torch.cat((total_preds, output.cpu()), 0)\n",
    "            total_labels = torch.cat((total_labels, data.y.view(-1, 1).cpu()), 0)\n",
    "    return total_labels.numpy().flatten(), total_preds.numpy().flatten()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "25DTI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
